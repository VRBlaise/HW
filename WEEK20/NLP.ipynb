{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb61f50",
   "metadata": {},
   "source": [
    "### Regular Expressions (RegEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01440c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194e7d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('abc', 'abcdef') # pattern as first argument, string as second argument, returns a match object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88cf770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('bc', 'abcdf') # no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de4d9246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 3), match='bc'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('bc', 'abcdf') # finds it inside the word, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f9b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 2), match='hi'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_regex = '\\w+' # special code for word\n",
    "re.match(word_regex, 'hi there!') # mathes the first word it finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad18e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'has', '2', 'cats']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_regex = '\\d'\n",
    "space_regex = '\\s'\n",
    "wildcard_regex = '.*'\n",
    "brackets_regex = r\"\\[.*\\]\" # finds anyhting in brakets backslash are escape characters, so that bracket means bracket\n",
    "script_regex = r\"[\\w\\s]+:\" # finds the script notation and the word or space before\n",
    "greedy_regex = 'a+' # gets aaaaas, can be 'a*' also\n",
    "nospace_regex = '\\S' # uppercase version negates them\n",
    "lowercase_regex = '[a-z]' # looks for group of letters\n",
    "# or is |\n",
    "# group is defined by ()\n",
    "# explicit character ranges are defined by []\n",
    "# usefull: split, findall, search, match\n",
    "# pattern goes first, string second\n",
    "# returns an iterator, string, match object\n",
    "\n",
    "match_digits_and_words = ('(\\d+|\\w+)')\n",
    "re.findall(match_digits_and_words, 'He has 2 cats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb373f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [A-Z] A to Z included\n",
    "# (A-Z) A and - and Z\n",
    "# [A-Za-z] A to Z and a to z, so both lower and upper\n",
    "# [A-Za-z\\-\\.] the above and - and .\n",
    "# (\\s+|,) spaces or coma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d357ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['split', 'on', 'spaces']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('\\s+', 'split on spaces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7252fae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', 's', 'write', 'RegEx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+', \"Let's write RegEx!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c935c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\s+', \"Let's write RegEx!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9298c1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 't', 's', 'w', 'r', 'i', 't', 'e', 'e', 'g', 'x']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[a-z]\", \"Let's write RegEx!\") # finds only the lowercase ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b26f496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L', 'e', 't', 's', 'w', 'r', 'i', 't', 'e', 'R', 'e', 'g', 'E', 'x']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w', \"Let's write RegEx!\") # apparently these are all letters, no spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d52810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's write RegEx\", \"  Won't that be fun\", '  I sure think so', '  Can you find 4 sentences', '  Or perhaps, all 19 words', '']\n",
      "['Let', 'RegEx', 'Won', 'Can', 'Or']\n",
      "[\"Let's\", 'write', 'RegEx!', \"Won't\", 'that', 'be', 'fun?', 'I', 'sure', 'think', 'so.', 'Can', 'you', 'find', '4', 'sentences?', 'Or', 'perhaps,', 'all', '19', 'words?']\n",
      "['4', '19']\n"
     ]
    }
   ],
   "source": [
    "my_string = \"Let's write RegEx!  Won't that be fun?  I sure think so.  Can you find 4 sentences?  Or perhaps, all 19 words?\"\n",
    "\n",
    "# Write a pattern to match sentence endings: sentence_endings\n",
    "sentence_endings = r\"[.?!]\"\n",
    "\n",
    "# Split my_string on sentence endings and print the result\n",
    "print(re.split(sentence_endings, my_string))\n",
    "\n",
    "# Find all capitalized words in my_string and print the result\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "print(re.findall(capitalized_words, my_string))\n",
    "\n",
    "# Split my_string on spaces and print the result\n",
    "spaces = r\"\\s+\"\n",
    "print(re.split(spaces, my_string))\n",
    "\n",
    "# Find all digits in my_string and print the result\n",
    "digits = r\"\\d+\"\n",
    "print(re.findall(digits, my_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e7beed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'there', '!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize # tokens are smaller units of language\n",
    "word_tokenize('Hi there!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32e0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize\n",
    "# regexp_tokenize is based on a regular expression pattern\n",
    "# TweetTokenizer a special class just for tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1afa84cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iste', 'audacia', ',', 'tuus', 'Quem', 'Quo', 'Quam', 'finem', 'nos', 'etiam', '?', 'patientia', 'ad', 'eludet', 'sese', 'iactabit', 'usque', 'furor', 'nostra', 'diu', 'tandem', 'abutere', 'Catilina', 'effrenata'}\n"
     ]
    }
   ],
   "source": [
    "scene_one = \"Quo usque tandem abutere, Catilina, patientia nostra? Quam diu etiam furor iste tuus nos eludet? Quem ad finem sese effrenata iactabit audacia?\"\n",
    "\n",
    "# Import necessary modules\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "\n",
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(scene_one)\n",
    "\n",
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "\n",
    "# Print the unique tokens result\n",
    "print(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdc9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
