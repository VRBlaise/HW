{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f402bb",
   "metadata": {},
   "source": [
    "### 1. Using the documentation for Recursive Feature Selection, apply this process to the crime dataset to create the best multivariate linear regression model. You can select what you’re trying to predict, but be sure to indicate what that is. Be sure to explain what RFE is in the markdown. You should be able to answer this using what’s on the documentation page + what you already know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87ff44",
   "metadata": {},
   "source": [
    "Recursive feature elimination (RFE) is a technique that selects features recursively starting from an initial set of features, until the optimal set of features (of chosen size) is reached. It uses an estimator that assigns weights to features, then in every round the least important feature is dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3276a1",
   "metadata": {},
   "source": [
    "X1 = total overall reported crime rate per 1 million residents\n",
    "\n",
    "X2 = reported violent crime rate per 100,000 residents\n",
    "\n",
    "X3 = annual police funding in $/resident\n",
    "\n",
    "X4 = % of people 25 years+ with 4 yrs. of high school\n",
    "\n",
    "X5 = % of 16 to 19 year-olds not in highschool and not highschool graduates.\n",
    "\n",
    "X6 = % of 18 to 24 year-olds in college\n",
    "\n",
    "X7 = % of people 25 years+ with at least 4 years of college\n",
    "\n",
    "Reference: Life In America's Small Cities, By G.S. Thomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3239f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478</td>\n",
       "      <td>184</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494</td>\n",
       "      <td>213</td>\n",
       "      <td>32</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2  X3  X4  X5  X6  X7\n",
       "0  478  184  40  74  11  31  20\n",
       "1  494  213  32  72  11  43  18"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "crime_df = pd.read_csv(\"crime_data.csv\")\n",
    "crime_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5881adea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = crime_df[['X2','X3','X4','X5','X6','X7']]\n",
    "y = crime_df['X1']\n",
    "\n",
    "estimator = SVR(kernel = 'linear')\n",
    "selector = RFE(estimator,  n_features_to_select=3, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4ae8169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 1, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e6057",
   "metadata": {},
   "source": [
    "Based on this we select X3, X4 and X5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b71e3",
   "metadata": {},
   "source": [
    "Here we selected 3 features, but we do not really know yet how many we shall select. In order to do that we can iterate through the number of possible features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4ddf6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 1 and the corresponding score: 0.05735147028252985\n",
      "Number of features selected: 2 and the corresponding score: 0.2077037097161889\n",
      "Number of features selected: 3 and the corresponding score: 0.24702845263390028\n",
      "Number of features selected: 4 and the corresponding score: 0.2483870693553456\n",
      "Number of features selected: 5 and the corresponding score: 0.2575267216135815\n",
      "Number of features selected: 6 and the corresponding score: 0.5841293980921582\n"
     ]
    }
   ],
   "source": [
    "def get_selectors():\n",
    "    selectors = dict()\n",
    "    for i in range(1, 7):\n",
    "        estimator = SVR(kernel = 'linear')\n",
    "        selector = RFE(estimator,  n_features_to_select=i, step=1)\n",
    "        selectors[str(i)] = selector\n",
    "    return selectors\n",
    "\n",
    "def evaluate_model(selector, X, y):\n",
    "    selector = selector.fit(X, y)\n",
    "    score = selector.score(X, y)\n",
    "    return score\n",
    "\n",
    "# get the models to evaluate\n",
    "selectors = get_selectors()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, keys = list(), list()\n",
    "\n",
    "for key, selector in selectors.items():\n",
    "    scores = evaluate_model(selector, X, y)\n",
    "    results.append(scores)\n",
    "    keys.append(key)\n",
    "    print(f'Number of features selected: {key} and the corresponding score: {np.mean(scores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ece68",
   "metadata": {},
   "source": [
    "6 has the best score (which means we did not select any features), but that is likely because it is overfitted. I am sure there is a system which puts a penalty on using too many features..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2912f",
   "metadata": {},
   "source": [
    "### 2. Create a function called rec_digit_sum that takes in an integer. This function is the recursive sum of all the digits in a number. Given n, take the sum of all the digits in n. If the resulting value has more than one digit, continue calling the function in this way until a single-digit number is produced. The input will be a non-negative integer, and this should work for extremely large values as well as for single-digit inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32154ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_digit_sum(n):\n",
    "    try:\n",
    "        if not n%1 == 0:\n",
    "            raise ValueError('This function works only with integers')\n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "    else:\n",
    "        digit_sum = 0\n",
    "        for digit in str(n):\n",
    "            digit_sum += int(digit)        \n",
    "        return digit_sum if len(str(digit_sum)) == 1 else rec_digit_sum(digit_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dc0dc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_digit_sum(335795147896541233114569874463211126955522332555223669841489665)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c8b7d",
   "metadata": {},
   "source": [
    "### 3. Create a list of preprocessing steps you should try when working to build a model. Briefly describe what each step is. Work with your group to come up with the most comprehensive list you can."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62abf72",
   "metadata": {},
   "source": [
    "#### 1. Data Extraction\n",
    "\n",
    "There are many possible sources of data (from customers, from the web, through measurements): it is crucial to understand how the data was acquired before manipulationg it.\n",
    "\n",
    "#### 2. Data Cleaning\n",
    "\n",
    "Main aim is to get rid of redundancies. Possible sources of error include:\n",
    "- duplicated entries\n",
    "- error in accuracy\n",
    "- the data entires might have been altered (consistency)\n",
    "- missing values\n",
    "\n",
    "Ways to eliminate sources of errors:\n",
    "\n",
    "- removing duplicates\n",
    "- keeping track of dates of updates (assumption is, most recent data is most correct)\n",
    "- filling in missing values\n",
    "\n",
    "#### 3. Data integration\n",
    "\n",
    "Data might be acquired from different sources and thus not consistent. Consistency issues have to be resolved prior to use\n",
    "\n",
    "#### 4. Data Transformation\n",
    "\n",
    "The model to be built might need other formats then the raw data, possible transformations include:\n",
    "\n",
    "- normalization (to enable scaling of data)\n",
    "- aggregation (defining new features from multiple old features)\n",
    "- generalization (lower level attributes are converted to higher standard)\n",
    "\n",
    "#### 5. Data reduction\n",
    "\n",
    "Redundancies from the data are removed\n",
    "\n",
    "The following two steps can help better understand the needs to be satisfied using the steps above.\n",
    "\n",
    "#### 6. In depth data exploration\n",
    "\n",
    "Aims understanding essential patterns appearing in the data.\n",
    "\n",
    "#### 7. Identifying the critical features\n",
    "\n",
    "Feature engineering as well as identification of constant and variable features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c6b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
