{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0098d64",
   "metadata": {},
   "source": [
    "### 1. Look up the Adam optimization functions in PyTorch https://pytorch.org/docs/stable/optim.html . How does it work? Try at least one other optimization function with the diabetes dataset shown in class. How does the model perform with the new optimizer? Did it perform better or worse than Adam? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026eb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a90e62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('../WEEK17/diabetes.csv')\n",
    "diabetes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd65b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1).values\n",
    "y = diabetes_df['Outcome'].values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "# #Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fea686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # activation functions\n",
    "\n",
    "# create tensors\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial neural network\n",
    "\n",
    "class ANN_Model(nn.module):\n",
    "    def __init__(self, input_features = 8, hidden1 = 20, hidden2 = 20, out_features = 2):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1, hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b68bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_list = [torch.optim.Adadelta, torch.optim.Adagrad, torch.optim.Adam, torch.optim.AdamW,\n",
    "                  torch.optim.Adamax, torch.optim.ASGD, torch.optim.NAdam, torch.optim.RAdam, torch.optim.RMSprop, \n",
    "                  torch.optim.Rprop, torch.optim.SGD]\n",
    "\n",
    "for x in optimizer_list:\n",
    "    \n",
    "    #optimizer\n",
    "    optimizer = x(ann.parameters(), lr=0.1)\n",
    "    \n",
    "    #run model through multiple epochs/iterations\n",
    "    final_loss = []\n",
    "    n_epochs = 501\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = ann.forward(X_train)\n",
    "        loss = loss_function(y_pred, y_train)\n",
    "        final_loss.append(loss)\n",
    "\n",
    "        if epoch == 500:\n",
    "            print(f'Optimizer {x}: Epoch number {epoch} with loss, {loss}')\n",
    "\n",
    "        # impliment optimizer\n",
    "        # gradient descent - zero the gradient before running backwards propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #perform optimization step for each epoch\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 500 and loss < 0.1:\n",
    "            #predictions \n",
    "            y_pred = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(X_test):\n",
    "                    prediction = ann(data)\n",
    "                    y_pred.append(prediction.argmax())\n",
    "\n",
    "            from sklearn.metrics import classification_report\n",
    "            print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60f39e",
   "metadata": {},
   "source": [
    "### 2. Write a function that lists and counts the number of divisors for an input value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c06f140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_divisors(n):\n",
    "    divisors = [n]\n",
    "    for i in range(1, (n//2 + 1)):\n",
    "        if n%i == 0:\n",
    "            divisors.append(i)\n",
    "    else:\n",
    "        pass\n",
    "    divisors.sort()\n",
    "    \n",
    "    my_string = str(n) + ' has ' + str(len(divisors)) + ' divisors: '\n",
    "    for i in range(len(divisors)):\n",
    "        if i == (len(divisors) - 1):\n",
    "            my_string = my_string + ' & ' + str(divisors[i])\n",
    "        elif i == 0:\n",
    "            my_string = my_string + str(divisors[i])\n",
    "        else:\n",
    "            my_string = my_string + ', ' + str(divisors[i])\n",
    "    return my_string\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a89727cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'55 has 4 divisors: 1, 5, 11 & 55'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_divisors(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b68f231a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'120 has 16 divisors: 1, 2, 3, 4, 5, 6, 8, 10, 12, 15, 20, 24, 30, 40, 60 & 120'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_divisors(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c083056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
